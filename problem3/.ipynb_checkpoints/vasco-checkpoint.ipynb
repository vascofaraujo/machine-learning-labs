{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6484c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from sklearn.metrics import balanced_accuracy_score as BACC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import eval_scores as eval\n",
    "import cv2 as cv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ee13ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(xtrain, ytrain):\n",
    "    print(xtrain.shape, ytrain.shape)\n",
    "    #(6470, 50, 50) (6470,)\n",
    "    #(50, 50) ()\n",
    "    xtrain_len = len(xtrain)\n",
    "    \n",
    "    aug_xtrain = np.zeros((xtrain_len*2, 50, 50))\n",
    "    aug_ytrain = np.zeros((xtrain_len*2))\n",
    "    \n",
    "    aug_xtrain[0:xtrain_len, :, :] = xtrain\n",
    "    aug_ytrain[0:xtrain_len] = ytrain\n",
    "    \n",
    "    for idx in range(xtrain_len):\n",
    "        image = xtrain[idx,:,:]\n",
    "        label = ytrain[idx]\n",
    "                \n",
    "        angle = int(random.uniform(-90, 90))\n",
    "        h, w = image.shape[0], image.shape[1]\n",
    "        M = cv.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "        rotated = cv.warpAffine(image, M, (w, h))\n",
    "        \n",
    "        flipped = cv.flip(rotated, 1)\n",
    "\n",
    "\n",
    "        aug_xtrain[xtrain_len+idx] = flipped\n",
    "        aug_ytrain[xtrain_len+idx] = label\n",
    "        \n",
    "        \n",
    "    return aug_xtrain, aug_ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc81ba2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6470, 50, 50) (6470,)\n"
     ]
    }
   ],
   "source": [
    "xtrain = np.load(\"Xtrain_Classification_Part1.npy\")\n",
    "ytrain = np.load(\"Ytrain_Classification_Part1.npy\")\n",
    "xtrain_len = len(xtrain)\n",
    "ytrain_len = len(ytrain)\n",
    "\n",
    "#Reshape Images\n",
    "xtrain = xtrain.reshape((xtrain_len,50,50))\n",
    "mean = xtrain.mean(axis=(0, 1, 2)) \n",
    "std = xtrain.std(axis=(0, 1, 2))\n",
    "\n",
    "xtrain = (xtrain - mean)/std  \n",
    "\n",
    "xtrain, ytrain = augment_data(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc4d8a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xtrain[6479,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dab60c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xtrain = np.load(\"Xtrain_Classification_Part1.npy\")\n",
    "        ytrain = np.load(\"Ytrain_Classification_Part1.npy\")\n",
    "        xtest = np.load(\"Xtest_Classification_Part1.npy\")\n",
    "\n",
    "\n",
    "        xtrain_len = len(xtrain)\n",
    "        ytrain_len = len(ytrain)\n",
    "        xtest_len = len(xtest)\n",
    "\n",
    "        #Reshape Images\n",
    "        xtrain = xtrain.reshape((xtrain_len,50,50))\n",
    "        mean = xtrain.mean(axis=(0, 1, 2)) \n",
    "        std = xtrain.std(axis=(0, 1, 2))\n",
    "\n",
    "        xtrain = (xtrain - mean)/std  \n",
    "        \n",
    "        xtrain, ytrain = augment_data(xtrain, ytrain)\n",
    "        \n",
    "        new_xtrain_len = len(xtrain)\n",
    "        new_ytrain_len = len(ytrain)\n",
    "        \n",
    "        self.xtrain = xtrain.reshape((new_xtrain_len,1,50,50))\n",
    "        self.xtest = xtest.reshape((xtest_len,1,50,50))\n",
    "\n",
    "        self.ytrain = ytrain.reshape(new_ytrain_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xtrain)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #mage = self.xtrain[idx,:,:,:].reshape((50,50))\n",
    "        #image = cv.resize(image, (25,25))\n",
    "        #image = image.reshape(1,25,25)\n",
    "        \n",
    "        image = self.xtrain[idx, :, :, :]\n",
    "        label = self.ytrain[idx]\n",
    "        \n",
    "\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ff07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClassifyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10,\n",
    "                              kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20,\n",
    "                              kernel_size=5, stride=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(in_features=1620, out_features=800)\n",
    "        self.fc2 = nn.Linear(in_features=1620, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        #x = self.fc1(x)\n",
    "        #x = F.relu(x)\n",
    "        \n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "301b424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size' : 64,\n",
    "    'lr' : 0.001,\n",
    "    'momentum' : 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca190a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \n",
    "    num_epochs = 400\n",
    "    best_score = 1.0\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        for idx, data in enumerate(train_loader):\n",
    "            image, label = data[0].float().to(device), data[1].float()\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            classify_output = model(image)\n",
    "            \n",
    "            \n",
    "            y_true = torch.reshape(label.cpu(), (-1,))\n",
    "            y_pred = torch.reshape(classify_output.cpu(), (-1,))\n",
    "            \n",
    "            loss = criterion(y_pred, y_true)\n",
    "            \n",
    "            train_loss.append(loss)\n",
    "\n",
    "            #print(loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print for mini batches\n",
    "            running_loss += loss.item()\n",
    "            if idx % 50 == 49:  # every 50 mini batches\n",
    "                print('[Epoch %d, %5d Mini Batches] loss: %.3f' %\n",
    "                      (epoch + 1, idx + 1, running_loss/50))\n",
    "                running_loss = 0.0\n",
    "               \n",
    "        model.eval()\n",
    "        test_score = 0.0\n",
    "        \n",
    "         \n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(test_loader):\n",
    "                image, label = data[0].float().to(device), data[1].float()\n",
    "\n",
    "                classify_output = model(image)\n",
    "\n",
    "                y_true = torch.reshape(label.cpu(), (-1,))\n",
    "                y_pred = torch.reshape(classify_output.cpu(), (-1,))\n",
    "\n",
    "                test_loss = criterion(y_pred, y_true)\n",
    "                \n",
    "                val_loss.append(test_loss)\n",
    "\n",
    "                test_score += test_loss\n",
    "\n",
    "            test_score /= len(test_loader)\n",
    "\n",
    "            print(test_score)\n",
    "\n",
    "            if test_score < best_score:\n",
    "                torch.save(model, \"ClassifyNet.pth\")\n",
    "                best_score = test_score\n",
    "        \n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc1d7acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6470, 50, 50) (6470,)\n"
     ]
    }
   ],
   "source": [
    "data_set = ImageDataset()\n",
    "\n",
    "train_set, test_set = train_test_split(data_set, test_size=0.2, random_state=1, shuffle=True)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf166f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a11251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device= torch.device('cpu')\n",
    "model = ClassifyNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=config['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e8036ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifyNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=1620, out_features=800, bias=True)\n",
      "  (fc2): Linear(in_features=1620, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862bd8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1,    50 Mini Batches] loss: 0.676\n",
      "[Epoch 1,   100 Mini Batches] loss: 0.653\n",
      "[Epoch 1,   150 Mini Batches] loss: 0.630\n",
      "tensor(0.6022)\n",
      "[Epoch 2,    50 Mini Batches] loss: 0.610\n",
      "[Epoch 2,   100 Mini Batches] loss: 0.595\n",
      "[Epoch 2,   150 Mini Batches] loss: 0.576\n",
      "tensor(0.5635)\n",
      "[Epoch 3,    50 Mini Batches] loss: 0.584\n",
      "[Epoch 3,   100 Mini Batches] loss: 0.571\n",
      "[Epoch 3,   150 Mini Batches] loss: 0.567\n",
      "tensor(0.5481)\n",
      "[Epoch 4,    50 Mini Batches] loss: 0.563\n",
      "[Epoch 4,   100 Mini Batches] loss: 0.557\n",
      "[Epoch 4,   150 Mini Batches] loss: 0.546\n",
      "tensor(0.5314)\n",
      "[Epoch 5,    50 Mini Batches] loss: 0.560\n",
      "[Epoch 5,   100 Mini Batches] loss: 0.544\n",
      "[Epoch 5,   150 Mini Batches] loss: 0.539\n",
      "tensor(0.5202)\n",
      "[Epoch 6,    50 Mini Batches] loss: 0.532\n",
      "[Epoch 6,   100 Mini Batches] loss: 0.538\n",
      "[Epoch 6,   150 Mini Batches] loss: 0.520\n",
      "tensor(0.5055)\n",
      "[Epoch 7,    50 Mini Batches] loss: 0.528\n",
      "[Epoch 7,   100 Mini Batches] loss: 0.525\n",
      "[Epoch 7,   150 Mini Batches] loss: 0.523\n",
      "tensor(0.5072)\n",
      "[Epoch 8,    50 Mini Batches] loss: 0.516\n",
      "[Epoch 8,   100 Mini Batches] loss: 0.509\n",
      "[Epoch 8,   150 Mini Batches] loss: 0.514\n",
      "tensor(0.4885)\n",
      "[Epoch 9,    50 Mini Batches] loss: 0.502\n",
      "[Epoch 9,   100 Mini Batches] loss: 0.506\n",
      "[Epoch 9,   150 Mini Batches] loss: 0.519\n",
      "tensor(0.4861)\n",
      "[Epoch 10,    50 Mini Batches] loss: 0.513\n",
      "[Epoch 10,   100 Mini Batches] loss: 0.495\n",
      "[Epoch 10,   150 Mini Batches] loss: 0.491\n",
      "tensor(0.4756)\n",
      "[Epoch 11,    50 Mini Batches] loss: 0.493\n",
      "[Epoch 11,   100 Mini Batches] loss: 0.490\n",
      "[Epoch 11,   150 Mini Batches] loss: 0.497\n",
      "tensor(0.4808)\n",
      "[Epoch 12,    50 Mini Batches] loss: 0.493\n",
      "[Epoch 12,   100 Mini Batches] loss: 0.496\n",
      "[Epoch 12,   150 Mini Batches] loss: 0.475\n",
      "tensor(0.4660)\n",
      "[Epoch 13,    50 Mini Batches] loss: 0.473\n",
      "[Epoch 13,   100 Mini Batches] loss: 0.487\n",
      "[Epoch 13,   150 Mini Batches] loss: 0.482\n",
      "tensor(0.4640)\n",
      "[Epoch 14,    50 Mini Batches] loss: 0.484\n",
      "[Epoch 14,   100 Mini Batches] loss: 0.469\n",
      "[Epoch 14,   150 Mini Batches] loss: 0.480\n",
      "tensor(0.4581)\n",
      "[Epoch 15,    50 Mini Batches] loss: 0.473\n",
      "[Epoch 15,   100 Mini Batches] loss: 0.476\n",
      "[Epoch 15,   150 Mini Batches] loss: 0.465\n",
      "tensor(0.4526)\n",
      "[Epoch 16,    50 Mini Batches] loss: 0.460\n",
      "[Epoch 16,   100 Mini Batches] loss: 0.484\n",
      "[Epoch 16,   150 Mini Batches] loss: 0.457\n",
      "tensor(0.4486)\n",
      "[Epoch 17,    50 Mini Batches] loss: 0.466\n",
      "[Epoch 17,   100 Mini Batches] loss: 0.461\n",
      "[Epoch 17,   150 Mini Batches] loss: 0.455\n",
      "tensor(0.4549)\n",
      "[Epoch 18,    50 Mini Batches] loss: 0.465\n",
      "[Epoch 18,   100 Mini Batches] loss: 0.462\n",
      "[Epoch 18,   150 Mini Batches] loss: 0.461\n",
      "tensor(0.4442)\n",
      "[Epoch 19,    50 Mini Batches] loss: 0.464\n",
      "[Epoch 19,   100 Mini Batches] loss: 0.444\n",
      "[Epoch 19,   150 Mini Batches] loss: 0.460\n",
      "tensor(0.4334)\n",
      "[Epoch 20,    50 Mini Batches] loss: 0.444\n",
      "[Epoch 20,   100 Mini Batches] loss: 0.449\n",
      "[Epoch 20,   150 Mini Batches] loss: 0.451\n",
      "tensor(0.4350)\n",
      "[Epoch 21,    50 Mini Batches] loss: 0.448\n",
      "[Epoch 21,   100 Mini Batches] loss: 0.442\n",
      "[Epoch 21,   150 Mini Batches] loss: 0.446\n",
      "tensor(0.4299)\n",
      "[Epoch 22,    50 Mini Batches] loss: 0.433\n",
      "[Epoch 22,   100 Mini Batches] loss: 0.437\n",
      "[Epoch 22,   150 Mini Batches] loss: 0.456\n",
      "tensor(0.4313)\n",
      "[Epoch 23,    50 Mini Batches] loss: 0.431\n",
      "[Epoch 23,   100 Mini Batches] loss: 0.443\n",
      "[Epoch 23,   150 Mini Batches] loss: 0.444\n",
      "tensor(0.4343)\n",
      "[Epoch 24,    50 Mini Batches] loss: 0.428\n",
      "[Epoch 24,   100 Mini Batches] loss: 0.439\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8594b184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'ClassifyNet' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95c1b03641e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test model against training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ClassifyNet.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'ClassifyNet' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# Test model against training data\n",
    "\n",
    "model = torch.load(\"ClassifyNet.pth\")\n",
    "\n",
    "test_score = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        image, label = data[0].float().to(device), data[1].float()\n",
    "\n",
    "        classify_output = model(image)\n",
    "\n",
    "        y_true = torch.reshape(label.cpu(), (-1,)) > 0.5\n",
    "        y_pred = torch.reshape(classify_output.cpu(), (-1,)) > 0.5\n",
    "        \n",
    "        test_loss = BACC(y_pred.numpy(), y_true.numpy())\n",
    "\n",
    "        test_score += test_loss\n",
    "\n",
    "test_score /= len(test_loader)\n",
    "\n",
    "print(test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
