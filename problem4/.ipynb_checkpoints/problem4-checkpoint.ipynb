{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6484c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from sklearn.metrics import balanced_accuracy_score as BACC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import eval_scores as eval\n",
    "import cv2 as cv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee13ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(xtrain, ytrain):\n",
    "    print(xtrain.shape, ytrain.shape)\n",
    "    #(6470, 50, 50) (6470,)\n",
    "    #(50, 50) ()\n",
    "    xtrain_len = len(xtrain)\n",
    "    \n",
    "    aug_xtrain = np.zeros((xtrain_len*2, 50, 50))\n",
    "    aug_ytrain = np.zeros((xtrain_len*2))\n",
    "    \n",
    "    aug_xtrain[0:xtrain_len, :, :] = xtrain\n",
    "    aug_ytrain[0:xtrain_len] = ytrain\n",
    "    \n",
    "    for idx in range(xtrain_len):\n",
    "        image = xtrain[idx,:,:]\n",
    "        label = ytrain[idx]\n",
    "                \n",
    "        angle = int(random.uniform(-90, 90))\n",
    "        h, w = image.shape[0], image.shape[1]\n",
    "        M = cv.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "        rotated = cv.warpAffine(image, M, (w, h))\n",
    "        \n",
    "        flipped = cv.flip(rotated, 1)\n",
    "\n",
    "\n",
    "        aug_xtrain[xtrain_len+idx] = flipped\n",
    "        aug_ytrain[xtrain_len+idx] = label\n",
    "        \n",
    "        \n",
    "    return aug_xtrain, aug_ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9786ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_scores.py\tproblem4.ipynb\t__pycache__\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc81ba2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Xtrain_Classification_Part2.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bb9bf6045845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xtrain_Classification_Part2.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ytrain_Classification_Part2.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxtrain_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mytrain_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Xtrain_Classification_Part2.npy'"
     ]
    }
   ],
   "source": [
    "xtrain = np.load(\"Xtrain_Classification_Part2.npy\")\n",
    "ytrain = np.load(\"Ytrain_Classification_Part2.npy\")\n",
    "xtrain_len = len(xtrain)\n",
    "ytrain_len = len(ytrain)\n",
    "\n",
    "\n",
    "#Reshape Images\n",
    "xtrain = xtrain.reshape((xtrain_len,50,50))\n",
    "mean = xtrain.mean(axis=(0, 1, 2)) \n",
    "std = xtrain.std(axis=(0, 1, 2))\n",
    "\n",
    "#xtrain = (xtrain - mean)/std  \n",
    "\n",
    "#xtrain, ytrain = augment_data(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xtrain[300,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e10fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ytrain)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab60c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xtrain = np.load(\"Xtrain_Classification_Part2.npy\")\n",
    "        ytrain = np.load(\"Ytrain_Classification_Part2.npy\")\n",
    "        xtest = np.load(\"Xtest_Classification_Part2.npy\")\n",
    "\n",
    "\n",
    "        xtrain_len = len(xtrain)\n",
    "        ytrain_len = len(ytrain)\n",
    "        xtest_len = len(xtest)\n",
    "\n",
    "        #Reshape Images\n",
    "        xtrain = xtrain.reshape((xtrain_len,50,50))\n",
    "        #mean = xtrain.mean(axis=(0, 1, 2)) \n",
    "        #std = xtrain.std(axis=(0, 1, 2))\n",
    "\n",
    "        #xtrain = (xtrain - mean)/std  \n",
    "        \n",
    "        #xtrain, ytrain = augment_data(xtrain, ytrain)\n",
    "        \n",
    "        #new_xtrain_len = len(xtrain)\n",
    "       # new_ytrain_len = len(ytrain)\n",
    "        \n",
    "        self.xtrain = xtrain.reshape((xtrain_len,1,50,50))\n",
    "        self.xtest = xtest.reshape((xtest_len,1,50,50))\n",
    "\n",
    "        self.ytrain = ytrain.reshape(ytrain_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xtest)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    " \n",
    "        \n",
    "        image = self.xtest[idx, :, :, :]\n",
    "        label = self.ytrain[idx]\n",
    "        \n",
    "\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClassifyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10,\n",
    "                              kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20,\n",
    "                              kernel_size=5, stride=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(in_features=1620, out_features=400)\n",
    "        self.fc2 = nn.Linear(in_features=400, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size' : 16,\n",
    "    'lr' : 0.001,\n",
    "    'momentum' : 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca190a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \n",
    "    num_epochs = 400\n",
    "    best_score = 1.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        for idx, data in enumerate(train_loader):\n",
    "            image, label = data[0].float().to(device), data[1].float()\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            classify_output = model(image)\n",
    "            \n",
    "            print(classify_output)\n",
    "                \n",
    "            #print(label.shape)\n",
    "            \n",
    "            #print(label)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            y_true = torch.sigmoid(torch.reshape(label.cpu(), (-1,)))\n",
    "            y_pred = torch.reshape(classify_output.cpu(), (-1,))\n",
    "            \n",
    "            \n",
    "            loss = criterion(y_pred, y_true)\n",
    "\n",
    "            #print(loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print for mini batches\n",
    "            running_loss += loss.item()\n",
    "            if idx % 50 == 49:  # every 50 mini batches\n",
    "                print('[Epoch %d, %5d Mini Batches] loss: %.3f' %\n",
    "                      (epoch + 1, idx + 1, running_loss/50))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        test_score = 0.0\n",
    "        \n",
    "         \n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(test_loader):\n",
    "                image, label = data[0].float().to(device), data[1].float()\n",
    "\n",
    "                classify_output = model(image)\n",
    "\n",
    "                y_true = torch.sigmoid(torch.reshape(label.cpu(), (-1,)))\n",
    "                y_pred = torch.reshape(classify_output.cpu(), (-1,))\n",
    "\n",
    "\n",
    "                test_loss = criterion(y_pred, y_true)\n",
    "\n",
    "                test_score += test_loss\n",
    "\n",
    "            test_score /= len(test_loader)\n",
    "\n",
    "            #print(test_score)\n",
    "\n",
    "            if test_score < best_score:\n",
    "                torch.save(model, \"ClassifyNet.pth\")\n",
    "                best_score = test_score\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d7acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_set = ImageDataset()\n",
    "\n",
    "#train_set, test_set = train_test_split(data_set, test_size=0.2, random_state=1, shuffle=True)\n",
    "\n",
    "train_loader = DataLoader(data_set, batch_size=config['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf166f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device= torch.device('cpu')\n",
    "model = ClassifyNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=config['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862bd8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set = ImageDataset()\n",
    "print(len(train_set))\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594b184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test model against training data\n",
    "\n",
    "model = torch.load(\"ClassifyNet.pth\")\n",
    "\n",
    "predictions = np.zeros((len(test_set)))\n",
    "\n",
    "output = []\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        image = data[0].float().to(device)\n",
    "        classify_output = model(image)\n",
    "    \n",
    "        y_pred = (torch.reshape(classify_output.cpu(), (-1,)) > 0.5).numpy()\n",
    "        \n",
    "        predictions[idx] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f65aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"predictions.npy\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
