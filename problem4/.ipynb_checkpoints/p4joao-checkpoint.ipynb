{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095a7b49-e180-4783-af23-5b3658e696e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 27 12:41:20 2021\n",
    "\n",
    "@author: Jo√£o\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97df098-7fdd-4333-8a58-fb13f7b748a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#                   Part 1.1 - Data\n",
    "#----------------------------------------------------\n",
    "\n",
    "xtrain = np.load(\"xtrain.npy\")\n",
    "xtest = np.load(\"xtest.npy\")\n",
    "ytrain = np.load(\"ytrain.npy\")\n",
    "\n",
    "xtrain_len = len(xtrain)\n",
    "xtest_len = len(xtest)\n",
    "\n",
    "print(f\"xtrain_len: {xtrain_len}\")\n",
    "\n",
    "\n",
    "\n",
    "xtrain /= 255\n",
    "xtest /= 255\n",
    "\n",
    "#Show images\n",
    "#plt.imshow(xtrain[0])\n",
    "#plt.show()\n",
    "#plt.imshow(xtest[1])\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Split 20% of the training set into a validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(\n",
    "            xtrain, ytrain, test_size=0.2, train_size=0.8)\n",
    "\n",
    "#Convert train labels to one-hot encoding\n",
    "yval = tf.keras.utils.to_categorical(yval, 2)\n",
    "ytrain = tf.keras.utils.to_categorical(ytrain, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04be11-0358-445b-a2ff-95f797c263b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP \n",
    "\n",
    "mlp = tf.keras.Sequential()\n",
    "mlp.add(tf.keras.layers.Dense(50,input_shape=(2500,),activation='relu'))\n",
    "mlp.add(tf.keras.layers.Dense(25,activation='relu'))\n",
    "mlp.add(tf.keras.layers.Dense(2,activation='sigmoid'))\n",
    "mlp.summary()\n",
    "\n",
    "# Early Stopping\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "#%%\n",
    "mlp.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "fit = mlp.fit(xtrain, ytrain, validation_data=(xval, yval), batch_size=20, epochs=200, callbacks=[early_stop])\n",
    "#fit = mlp.fit(xtrain, ytrain, validation_data=(xval, yval), batch_size=200, epochs=200)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fit.history['loss'])\n",
    "plt.plot(fit.history['val_loss'])\n",
    "plt.title('MLP loss as a function of the number of\\nepochs (with early stopping)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6c05f-8646-41fb-a1ce-b96a311b6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = mlp.predict(xtest, batch_size=20)\n",
    "predict_labels_index = np.argmax(predict_labels, axis=1)\n",
    "\n",
    "np.save(\"y.npy\", predict_labels_index)\n",
    "\n",
    "ytrain = np.load(\"y.npy\")\n",
    "\n",
    "#mlp_score = accuracy_score(predict_labels_index, test_labels)\n",
    "#mlp_confusion = confusion_matrix(predict_labels_index, test_labels)\n",
    "\n",
    "#print('==== MLP with early stopping ====')\n",
    "#print('Accuracy score = ', mlp_score,'\\nConfusion matrix:\\n',mlp_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33bdf8e0-cbf1-4ea2-8a9f-8d124c688610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain_len: 7366\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2344/347185921.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#Convert train labels to one-hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0myval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m   \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "#       Part 1.3 - CNN\n",
    "#----------------------------------------------------\n",
    "\n",
    "xtrain = np.load(\"../../../Xtrain_Classification_Part2.npy\")\n",
    "xtest = np.load(\"../../../Xtest_Classification_Part2.npy\")\n",
    "ytrain = np.load(\"../../../Ytrain_Classification_Part2.npy\")\n",
    "\n",
    "xtrain_len = len(xtrain)\n",
    "xtest_len = len(xtest)\n",
    "\n",
    "print(f\"xtrain_len: {xtrain_len}\")\n",
    "\n",
    "\n",
    "#Reshape Images\n",
    "xtrain = xtrain.reshape((xtrain_len,50,50))\n",
    "xtest = xtest.reshape((xtest_len,50,50))\n",
    "\n",
    "\n",
    "#Add extra dimension\n",
    "xtrain = np.expand_dims(xtrain, axis=3)\n",
    "xtest = np.expand_dims(xtest, axis=3)\n",
    "\n",
    "xtrain /= 255\n",
    "xtest /= 255\n",
    "\n",
    "#Show images\n",
    "#plt.imshow(xtrain[0])\n",
    "#plt.show()\n",
    "#plt.imshow(xtest[1])\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# labels\n",
    "#labels = np.array([0,1])\n",
    "\n",
    "\n",
    "#Split 20% of the training set into a validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(\n",
    "            xtrain, ytrain, test_size=0.2, train_size=0.8)\n",
    "\n",
    "#Convert train labels to one-hot encoding\n",
    "yval = tf.keras.utils.to_categorical(yval, 2)\n",
    "ytrain = tf.keras.utils.to_categorical(ytrain, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13d294-8e3c-44b8-86d3-7136a0649e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cnn = tf.keras.Sequential()\n",
    "#layer 0\n",
    "cnn.add(tf.keras.layers.Conv2D(16, kernel_size=3, activation='relu', input_shape = (50,50,1)))\n",
    "#layer 1\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#layer 2\n",
    "cnn.add(tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
    "#layer 3\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#layer 4\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "#layer 5\n",
    "cnn.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "#layer 6\n",
    "cnn.add(tf.keras.layers.Dense(2,activation='sigmoid'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "cnn.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "fit = cnn.fit(xtrain, ytrain, validation_data=(xval, \n",
    "                        yval), batch_size=200, epochs=200, \n",
    "                        callbacks=[early_stop])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fit.history['loss'])\n",
    "plt.plot(fit.history['val_loss'])\n",
    "plt.title('CNN loss as a function of the number of\\nepochs (with early stopping)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "predict_labels = cnn.predict(xtest, batch_size=200)\n",
    "predict_labels_index = np.argmax(predict_labels, axis=1)\n",
    "# cnn_score = accuracy_score(predict_labels_index, test_labels)\n",
    "# cnn_confusion = confusion_matrix(predict_labels_index, test_labels)\n",
    "\n",
    "# print('==== CNN with early stopping ====')\n",
    "# print(\"Score: \", cnn_score)\n",
    "# print(\"Confusion matrix:\\n\", cnn_confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
